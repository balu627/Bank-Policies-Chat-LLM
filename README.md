**ğŸ¦ Bank Policy Assistant â€“ AI-Powered Policy Q&A (Learning Project)**

This project is part of my personal learning journey into AI, LLMs, embeddings, vector databases, and full-stack app building.
It is not a production system, but a structured, end-to-end hands-on project to understand:

PDF ingestion & chunking

Embedding generation

FAISS vector search

Using Gemini LLMs with structured JSON outputs

Retrieval-Augmented Generation (RAG)

Session-based chat

Streamlit UI + FastAPI backend

Bank policy domain logic

**ğŸ“Œ Project Summary**

This application lets a user ask banking queries such as:

â€œHow to apply for a credit card at SBI?â€

â€œWhat are the eligibility conditions for HDFC loan?â€

â€œWhat is the account opening process?â€

The system does RAG retrieval from bank policy PDF documents and generates an AI answer with three structured sections:
âœ… Section 1A â€” Summary (from policy documents only)

Uses only the retrieved PDF chunks.
no external knowledge.

âœ… Section 1B â€” Step-wise Process (from policy documents only)

Detailed procedural steps if the policy mentions them.
If not mentioned â†’ the model explicitly says so.

âœ… Section 2 â€” Sources

Shows:

Bank name

Document name

Clean snippet (AI fixes broken chunk boundaries)

Example:

Bank: SBI
Document: sbi-policy-for-the-issuance-and-conduct-of-credit-cards-2023.pdf
Snippet: "Credit Cards can be issued to MSMEs... assessed based on financial statements..."

âœ… Section 3 â€” Cost Saving Tips (general online info)

This section can use online/general banking knowledge,
but must state clearly:

â€œThis section is based on general/online information and not from the policy documents.â€

ğŸ§  Architecture Overview
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚        UI Layer        â”‚
                        â”‚     (Streamlit App)    â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚     FastAPI Backend    â”‚
                        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                        â”‚  /ask endpoint         â”‚
                        â”‚  Session store         â”‚
                        â”‚  RAG pipeline          â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚        Retrieval Layer (RAG)           â”‚
                 â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                 â”‚  FAISS Index per bank:                 â”‚
                 â”‚      storage/sbi/index.faiss           â”‚
                 â”‚      storage/hdfc/index.faiss          â”‚
                 â”‚      storage/common/index.faiss        â”‚
                 â”‚                                        â”‚
                 â”‚  Metadata per chunk (source file, id)  â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Gemini LLM (google-genai)     â”‚
                    â”‚  Structured JSON output only   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

**ğŸ—‚ï¸ Folder Structure**

Policy Bot/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ main.py           â†’ FastAPI server
â”‚   â”‚   â”œâ”€â”€ chat_logic.py     â†’ Gemini RAG + JSON logic
â”‚   â”‚   â”œâ”€â”€ session_store.py  â†’ Chat history per session
â”‚   â”‚
â”‚   â”œâ”€â”€ ingest/
â”‚   â”‚   â”œâ”€â”€ build_indexes.py  â†’ Creates FAISS indexes
â”‚   â”‚   â”œâ”€â”€ pdf_utils.py      â†’ PDF reading + chunking
â”‚   â”‚   â”œâ”€â”€ config.py         â†’ Data folder paths
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ common/               â†’ Generic PDFs
â”‚   â”œâ”€â”€ sbi/                  â†’ SBI PDFs
â”‚   â”œâ”€â”€ hdfc/                 â†’ HDFC PDFs
â”‚   â”œâ”€â”€ icici/                â†’ ICICI PDFs
â”‚
â”œâ”€â”€ storage/
â”‚   â”œâ”€â”€ common/               â†’ FAISS index + metadata.pkl
â”‚   â”œâ”€â”€ sbi/
â”‚   â”œâ”€â”€ hdfc/
â”‚
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ app.py                â†’ Streamlit floating chat UI
â”‚
â”œâ”€â”€ .env                      â†’ Gemini API key
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt

ğŸ”§ Setup Instructions
1ï¸âƒ£ Clone the project
git clone <your repo url>
cd "Policy Bot"

2ï¸âƒ£ Create & activate virtual environment
Windows:
python -m venv bankpolicy
bankpolicy\Scripts\activate

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

4ï¸âƒ£ Add your .env
GEMINI_API_KEY=your-key-here
GEMINI_MODEL=gemini-1.5-flash

5ï¸âƒ£ Place PDFs in the data/ folders

Example:

data/sbi/*.pdf
data/hdfc/*.pdf
data/common/*.pdf

6ï¸âƒ£ Build indexes
python -m backend.ingest.build_indexes

7ï¸âƒ£ Start backend (FastAPI)
uvicorn backend.api.main:app --reload

8ï¸âƒ£ Run UI
streamlit run ui/app.py


The UI opens at:

http://localhost:8501

âœ¨ Features & Highlights
âœ” Retrieval Augmented Generation (RAG)

Only policy chunks relevant to the question are sent to the LLM.

âœ” Bank-specific or general mode

If the user selects a bank â†’ search that bank + common
If no bank selected â†’ search all banks

âœ” Clean structured JSON

LLM is forced to output only valid JSON.
A custom parser (safe_parse_llm_json) handles messy outputs safely.

âœ” Session-based chat memory

Each chat session uses its own conversation history.

âœ” Floating search/chat UI

Streamlit UI replicates a modern chat-style experience.

âœ” Future-ready

Modular architecture allows easily adding:

More banks

Logging

Auth

Better vector engines (Qdrant, Pinecone)

